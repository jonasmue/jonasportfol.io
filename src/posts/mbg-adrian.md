---
title: 'ADRIAN: An Interaction Concept for Autonomous Driving'
date: '2015-08-15'
category: "User Centered Design"
image: "mbg-preview.png"
teaser: "In cooperation with Continental we created an interaction concept prototype for autonomous vehicles."
---

In cooperation with [Continental](https://www.continental-corporation.com/en) we created an interaction concept prototype 
for autonomous vehicles called **ADRIAN** â€” **A**utonomous **Dr**iving **I**ntelligence **A**nd **N**avigation. 
The project was part of the HCI bachelor module *User-Centered Design*.

Utilizing the Rapid Contextual Design approach^[Holtzblatt, K., Wendell, J. B., & Wood, S. (2004). Rapid contextual design: a how-to guide to key techniques for user-centered design. Elsevier.] 
we iteratively created several prototypes in a user-centered design process. Consolidating data from contextual inquiries 
in an **affinity diagram**, several important features emerged concerning an interaction concept with autonomous vehicles: 
the interaction and experience ought to be **comfortable**, include an interactive **voice assistant** and a 
**physical interaction device**. Furthermore, users felt an immediate need of **trust** and **control**, and demanded 
**clear and instant feedback** conveying the current system status. However, users did not want to use gestures as interaction technique.

After generating ideas from **visioning and storyboarding** processes, a first prototype was created to be tested with users. 
Iteratively refining the prototype after each interview, our final concept incorporated (1) a personal physical interaction device, 
(2) an intelligent voice-controlled assistant and (3) the classic interaction mechanisms of pedals and steering wheel.

![The first paper prototypes were put on a test car's windscreen on the outside in order to simulate the HUD.](/images/posts/mbg-p1.jpg)
<div class="caption">The first paper prototypes were put on a test car's windscreen on the outside in order to simulate the HUD.</div>

The interaction device is the heart of the car which can be plugged into a base inside the car for controlling different 
forms of actions, e.g. passing another car. But it also acts as car key as well as device for remote access, for example 
when one wants to call the car which is parked somewhere else. Touching the device whilst driving, the system enters a 
command mode where relevant actions are highlighted on a HUD on the windscreen. An eye-tracking system registers which 
element the controlling person is looking at and highlights context relevant actions. Tilting and pressing allows for 
choosing the different actions and maneuvers. We integrated this device to give the user a feeling of power and control.

![The physical interaction device can be plugged into the base inside the car (left) or used for remote control of the vehicle (right).](/images/posts/mbg-p2.jpg)
<div class="caption">The physical interaction device can be plugged into the base inside the car (left) or used for remote control of the vehicle (right).</div>


All actions can also be executed using voice commands allowing for a more natural and direct interaction. Users indicated 
that they preferred this form of interaction which however lacks the conveyance of power and trust. Therefore, it was 
important to us to integrate the redundant 2-channel interaction paradigm using speech or touch.

Finally, users expressed that they did not want to give up on driving themselves completely. Therefore, we integrated 
the classic steering devices (wheel and pedals) for manual driving. They are, however, retractable in order to not 
unnecessarily obscure the passenger space when the car is driving autonomously.

![The final prototype was a digital Wizard-of-Oz-prototype. Using a mobile projector it was projected on a test car's windscreen (left). The test instructor acted as Wizard reacting to a test person's input to the system.](/images/posts/mbg-p3.jpg)
<div class="caption">The final prototype was a digital Wizard-of-Oz-prototype. Using a mobile projector it was projected on a test car's windscreen (left). The test instructor acted as Wizard reacting to a test person's input to the system.</div>
